{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Lulu-Diffusion-Experiment/blob/main/notebook/INSTANTID_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "DvNCnzCg6aZN",
        "outputId": "797c6606-5338-4cbd-834c-33c14f6390ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2u537id6l4-",
        "outputId": "8c6af125-b462-4398-b055-bc913c6138be"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'INSTID'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 23 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (23/23), 6.75 MiB | 13.71 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/INSTID\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (11/11), 2.74 KiB | 1.37 MiB/s, done.\n",
            "Filtering content: 100% (5/5), 407.74 MiB | 165.62 MiB/s, done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2024-01-26 01:10:38.200203: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-26 01:10:38.200253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-26 01:10:38.201950: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-26 01:10:39.302651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ControlNetModel/config.json: 100% 1.38k/1.38k [00:00<00:00, 7.96MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 2.50G/2.50G [00:07<00:00, 328MB/s]\n",
            "ip-adapter.bin: 100% 1.69G/1.69G [00:04<00:00, 348MB/s]\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "set det-size: (640, 640)\n",
            "model_index.json: 100% 800/800 [00:00<00:00, 4.39MB/s]\n",
            "Fetching 18 files:   0% 0/18 [00:00<?, ?it/s]\n",
            "model.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model.safetensors:   0% 0.00/1.39G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "scheduler/scheduler_config.json: 100% 474/474 [00:00<00:00, 3.08MB/s]\n",
            "Fetching 18 files:  11% 2/18 [00:01<00:14,  1.10it/s]\n",
            "\n",
            "\n",
            "text_encoder_2/config.json: 100% 688/688 [00:00<00:00, 4.52MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/tokenizer_config.json: 100% 737/737 [00:00<00:00, 4.85MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 3.12MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  13% 31.5M/246M [00:00<00:00, 257MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "text_encoder/config.json: 100% 676/676 [00:00<00:00, 4.61MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   2% 31.5M/1.39G [00:00<00:05, 269MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  26% 62.9M/246M [00:00<00:00, 269MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:   5% 73.4M/1.39G [00:00<00:04, 318MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  43% 105M/246M [00:00<00:00, 305MB/s] \u001b[A\n",
            "\n",
            "model.safetensors:   8% 115M/1.39G [00:00<00:03, 338MB/s] \u001b[A\u001b[A\n",
            "model.safetensors:  60% 147M/246M [00:00<00:00, 333MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  11% 157M/1.39G [00:00<00:03, 353MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  77% 189M/246M [00:00<00:00, 359MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/tokenizer_config.json: 100% 725/725 [00:00<00:00, 4.35MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/special_tokens_map.json: 100% 460/460 [00:00<00:00, 2.69MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:  14% 199M/1.39G [00:00<00:03, 345MB/s]\u001b[A\u001b[A\n",
            "model.safetensors: 100% 246M/246M [00:00<00:00, 338MB/s]\n",
            "Fetching 18 files:  22% 4/18 [00:02<00:07,  1.76it/s]\n",
            "\n",
            "model.safetensors:  17% 241M/1.39G [00:00<00:03, 338MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 4.55MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 763kB/s]\n",
            "\n",
            "\n",
            "model.safetensors:  20% 283M/1.39G [00:00<00:03, 330MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/5.14G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "tokenizer_2/merges.txt: 100% 525k/525k [00:00<00:00, 68.7MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  23% 325M/1.39G [00:01<00:03, 302MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   0% 21.0M/5.14G [00:00<00:32, 158MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "unet/config.json: 100% 1.83k/1.83k [00:00<00:00, 10.7MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  26% 357M/1.39G [00:01<00:03, 301MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 52.4M/5.14G [00:00<00:27, 185MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "vae/config.json: 100% 709/709 [00:00<00:00, 3.81MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  19% 31.5M/167M [00:00<00:00, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  29% 398M/1.39G [00:01<00:03, 315MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 83.9M/5.14G [00:00<00:24, 210MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  44% 73.4M/167M [00:00<00:00, 302MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  32% 440M/1.39G [00:01<00:02, 320MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 115M/5.14G [00:00<00:20, 243MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  69% 115M/167M [00:00<00:00, 317MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  35% 482M/1.39G [00:01<00:02, 315MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   3% 157M/5.14G [00:00<00:17, 288MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  94% 157M/167M [00:00<00:00, 337MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors: 100% 167M/167M [00:00<00:00, 312MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   4% 199M/5.14G [00:00<00:15, 310MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  41% 566M/1.39G [00:01<00:02, 302MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   5% 241M/5.14G [00:00<00:17, 288MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  43% 598M/1.39G [00:01<00:02, 284MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer_2/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.17MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   5% 273M/5.14G [00:01<00:17, 278MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  45% 629M/1.39G [00:02<00:02, 273MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   6% 304M/5.14G [00:01<00:18, 265MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  48% 661M/1.39G [00:02<00:02, 268MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 336M/5.14G [00:01<00:18, 259MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  50% 692M/1.39G [00:02<00:02, 268MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 367M/5.14G [00:01<00:17, 273MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  53% 734M/1.39G [00:02<00:02, 289MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   8% 409M/5.14G [00:01<00:17, 274MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  55% 765M/1.39G [00:02<00:02, 288MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 451M/5.14G [00:01<00:16, 283MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  58% 807M/1.39G [00:02<00:01, 299MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 493M/5.14G [00:01<00:15, 297MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  61% 849M/1.39G [00:02<00:01, 308MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 524M/5.14G [00:01<00:16, 288MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  63% 881M/1.39G [00:02<00:01, 290MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  11% 566M/5.14G [00:02<00:15, 303MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  66% 923M/1.39G [00:03<00:01, 314MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 598M/5.14G [00:02<00:17, 264MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  69% 965M/1.39G [00:03<00:01, 323MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 640M/5.14G [00:02<00:16, 279MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  72% 1.01G/1.39G [00:03<00:01, 314MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  13% 682M/5.14G [00:02<00:14, 300MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  75% 1.05G/1.39G [00:03<00:01, 299MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  14% 724M/5.14G [00:02<00:14, 312MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  78% 1.08G/1.39G [00:03<00:01, 279MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  15% 765M/5.14G [00:02<00:17, 249MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  80% 1.11G/1.39G [00:03<00:01, 242MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 797M/5.14G [00:03<00:19, 227MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  82% 1.14G/1.39G [00:03<00:01, 212MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 828M/5.14G [00:03<00:20, 210MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  85% 1.17G/1.39G [00:04<00:01, 202MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 860M/5.14G [00:03<00:21, 196MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  87% 1.21G/1.39G [00:04<00:00, 194MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 881M/5.14G [00:03<00:22, 191MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  88% 1.23G/1.39G [00:04<00:00, 191MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 902M/5.14G [00:03<00:22, 189MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  90% 1.25G/1.39G [00:04<00:00, 188MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 923M/5.14G [00:03<00:24, 174MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  91% 1.27G/1.39G [00:04<00:00, 174MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 944M/5.14G [00:03<00:23, 178MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  93% 1.29G/1.39G [00:04<00:00, 177MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  19% 965M/5.14G [00:04<00:27, 152MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  94% 1.31G/1.39G [00:04<00:00, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  97% 1.34G/1.39G [00:05<00:00, 178MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 1.01G/5.14G [00:04<00:22, 182MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  98% 1.36G/1.39G [00:05<00:00, 170MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 1.03G/5.14G [00:04<00:23, 174MB/s]\u001b[A\n",
            "\n",
            "model.safetensors: 100% 1.38G/1.39G [00:05<00:00, 163MB/s]\u001b[A\u001b[A\n",
            "model.safetensors: 100% 1.39G/1.39G [00:05<00:00, 253MB/s]\n",
            "Fetching 18 files:  33% 6/18 [00:07<00:16,  1.41s/it]\n",
            "diffusion_pytorch_model.safetensors:  21% 1.07G/5.14G [00:04<00:25, 162MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  21% 1.10G/5.14G [00:04<00:23, 174MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  22% 1.13G/5.14G [00:04<00:21, 186MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 1.16G/5.14G [00:05<00:20, 196MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 1.20G/5.14G [00:05<00:19, 202MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 1.22G/5.14G [00:05<00:19, 203MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 1.24G/5.14G [00:05<00:19, 204MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 1.26G/5.14G [00:05<00:19, 199MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 1.29G/5.14G [00:05<00:19, 198MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  26% 1.31G/5.14G [00:05<00:19, 195MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  26% 1.34G/5.14G [00:06<00:19, 196MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 1.36G/5.14G [00:06<00:19, 194MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 1.38G/5.14G [00:06<00:19, 195MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 1.41G/5.14G [00:06<00:19, 190MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  28% 1.43G/5.14G [00:06<00:19, 186MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  28% 1.45G/5.14G [00:06<00:20, 184MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 1.47G/5.14G [00:06<00:20, 182MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 1.49G/5.14G [00:06<00:19, 188MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 1.51G/5.14G [00:06<00:19, 190MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  30% 1.53G/5.14G [00:07<00:18, 193MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  30% 1.56G/5.14G [00:07<00:17, 202MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  31% 1.59G/5.14G [00:07<00:16, 210MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  32% 1.63G/5.14G [00:07<00:15, 225MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  32% 1.66G/5.14G [00:07<00:14, 236MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  33% 1.69G/5.14G [00:07<00:13, 246MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  33% 1.72G/5.14G [00:07<00:13, 251MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  34% 1.75G/5.14G [00:07<00:12, 262MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  35% 1.79G/5.14G [00:07<00:11, 293MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  36% 1.84G/5.14G [00:08<00:10, 308MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  37% 1.88G/5.14G [00:08<00:10, 318MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  37% 1.92G/5.14G [00:08<00:09, 329MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  38% 1.96G/5.14G [00:08<00:09, 327MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  39% 2.00G/5.14G [00:08<00:10, 300MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  40% 2.03G/5.14G [00:08<00:10, 297MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  40% 2.08G/5.14G [00:08<00:09, 306MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 2.12G/5.14G [00:09<00:09, 321MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  42% 2.16G/5.14G [00:09<00:08, 346MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  43% 2.20G/5.14G [00:09<00:08, 344MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  44% 2.24G/5.14G [00:09<00:08, 349MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  45% 2.29G/5.14G [00:09<00:08, 327MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  45% 2.33G/5.14G [00:09<00:08, 318MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  46% 2.37G/5.14G [00:09<00:08, 332MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  47% 2.41G/5.14G [00:09<00:08, 336MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  48% 2.45G/5.14G [00:09<00:07, 345MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  49% 2.50G/5.14G [00:10<00:07, 349MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  50% 2.55G/5.14G [00:10<00:07, 366MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  50% 2.59G/5.14G [00:10<00:06, 372MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  51% 2.63G/5.14G [00:10<00:06, 370MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  52% 2.67G/5.14G [00:10<00:06, 367MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  53% 2.72G/5.14G [00:10<00:06, 346MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  54% 2.76G/5.14G [00:10<00:07, 329MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  55% 2.80G/5.14G [00:10<00:07, 327MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  55% 2.84G/5.14G [00:11<00:06, 331MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  56% 2.88G/5.14G [00:11<00:07, 319MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  57% 2.93G/5.14G [00:11<00:07, 313MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  58% 2.97G/5.14G [00:11<00:06, 313MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 3.01G/5.14G [00:11<00:06, 321MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 3.05G/5.14G [00:11<00:06, 329MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  60% 3.09G/5.14G [00:11<00:06, 340MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  61% 3.14G/5.14G [00:11<00:05, 352MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  62% 3.18G/5.14G [00:12<00:05, 360MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 3.22G/5.14G [00:12<00:05, 365MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  64% 3.26G/5.14G [00:12<00:05, 374MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  64% 3.30G/5.14G [00:12<00:04, 381MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  65% 3.34G/5.14G [00:12<00:04, 369MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  66% 3.39G/5.14G [00:12<00:04, 378MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  67% 3.43G/5.14G [00:12<00:04, 385MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  68% 3.47G/5.14G [00:12<00:04, 365MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  68% 3.51G/5.14G [00:13<00:04, 349MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  69% 3.55G/5.14G [00:13<00:04, 348MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  70% 3.60G/5.14G [00:13<00:04, 317MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  71% 3.64G/5.14G [00:13<00:04, 327MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 3.68G/5.14G [00:13<00:04, 349MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 3.72G/5.14G [00:13<00:03, 353MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  73% 3.76G/5.14G [00:13<00:04, 336MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  74% 3.81G/5.14G [00:13<00:03, 345MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  75% 3.85G/5.14G [00:13<00:03, 355MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  76% 3.89G/5.14G [00:14<00:03, 355MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  77% 3.93G/5.14G [00:14<00:03, 345MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  77% 3.97G/5.14G [00:14<00:03, 357MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  78% 4.03G/5.14G [00:14<00:02, 384MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  79% 4.07G/5.14G [00:14<00:02, 371MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  80% 4.11G/5.14G [00:14<00:02, 359MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  81% 4.15G/5.14G [00:14<00:02, 345MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  82% 4.19G/5.14G [00:14<00:02, 352MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  82% 4.24G/5.14G [00:15<00:02, 350MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  83% 4.28G/5.14G [00:15<00:02, 360MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  84% 4.32G/5.14G [00:15<00:02, 362MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  85% 4.36G/5.14G [00:15<00:02, 354MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  86% 4.40G/5.14G [00:15<00:02, 359MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  87% 4.45G/5.14G [00:15<00:01, 352MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  87% 4.49G/5.14G [00:15<00:01, 334MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  88% 4.53G/5.14G [00:15<00:01, 316MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  89% 4.57G/5.14G [00:16<00:01, 337MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  90% 4.61G/5.14G [00:16<00:01, 339MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 4.66G/5.14G [00:16<00:01, 339MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 4.70G/5.14G [00:16<00:01, 336MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  92% 4.74G/5.14G [00:16<00:01, 332MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  93% 4.78G/5.14G [00:16<00:01, 346MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  94% 4.82G/5.14G [00:16<00:00, 358MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  95% 4.87G/5.14G [00:16<00:00, 359MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  96% 4.91G/5.14G [00:16<00:00, 368MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  96% 4.95G/5.14G [00:17<00:00, 379MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  97% 4.99G/5.14G [00:17<00:00, 387MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  98% 5.03G/5.14G [00:17<00:00, 330MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  99% 5.08G/5.14G [00:17<00:00, 295MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  99% 5.11G/5.14G [00:17<00:00, 253MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors: 100% 5.14G/5.14G [00:17<00:00, 287MB/s]\n",
            "Fetching 18 files: 100% 18/18 [00:20<00:00,  1.14s/it]\n",
            "The config attributes {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} were passed to StableDiffusionXLInstantIDPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
            "Keyword arguments {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False, 'safety_checker': None} are not expected by StableDiffusionXLInstantIDPipeline and will be ignored.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  4.70it/s]\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://576afcffb204c5c387.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "Start inference...\n",
            "[Debug] Prompt: a batman, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: a batman, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: a batman, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: a man wearing lab coat and glasses, holding a clipboard, standing inside a research facility, character portrait, 1 9 6 0 s, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by wlop, charlie bowater and alexandra fomina, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: Beautiful anime girl with short white hair, wearing lab coat and glasses, holding a clipboard, standing inside a research facility, character portrait, 1 9 6 0 s, long hair, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by wlop, charlie bowater and alexandra fomina, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: bruce wayne with batsuit in batman movie, full body, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: batman, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: superman, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: superman, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: a girl with god in an cloud on the background. art by greg rutkowski, artgerm, alphonse mucha, spike painting, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: A very beautiful savage symmetric girl with many jellyfish embedded, fantastic forest, fantasy, ghosts, surrounded by roots, portrait, sharp focus, intricate, elegant, digital painting, artstation, matte, highly detailed, concept art, illustration, ambient lighting, art by ilya kuvshinov, artgerm, alphonse mucha, and greg rutkowski, midsonmar, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: A ultradetailed beautiful panting of a stylish yangzi wearing intimate streetwear in a convenience store, oil painting, by ilya kuvshinov, greg rutkowski and makoto shinkai, heavenly beauty, very barely dressed, \n",
            "[Debug] Neg Prompt:  (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
          ]
        }
      ],
      "source": [
        "#@title 2. Launch the InstantID Gradio Demo\n",
        "#@markdown Run the cell, wait for everything to download and then click on the public URL.</br>\n",
        "%cd /content\n",
        "!git clone https://github.com/aitrepreneur/INSTID\n",
        "%cd /content/INSTID\n",
        "\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/Aitrepreneur/models\n",
        "\n",
        "!pip install -q insightface onnxruntime diffusers accelerate gradio==4.15.0\n",
        "!pip install -q https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl\n",
        "\n",
        "!python app.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}